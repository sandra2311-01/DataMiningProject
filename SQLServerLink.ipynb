{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87e9e54c-3071-4b10-8e1f-b594c268cf8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing file executed successfully.\n"
     ]
    }
   ],
   "source": [
    "%run \"Preprocessing.ipynb\"  # Run Preprocessing notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee5623f9-a536-4862-a0b9-f2d9b544c698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call your functions\n",
    "df_features, df_sales, df_stores = read_csv_files()\n",
    "df_features, df_sales = process_dates(df_features, df_sales)\n",
    "df_merged = merge_datasets(df_sales, df_features, df_stores)\n",
    "df_filled = fill_missing_values(df_merged)\n",
    "df_extracted = extract_date_components(df_filled)\n",
    "df_final, dropped_columns = preprocessing()\n",
    "\n",
    "# Add ID column to df_final and dropped_columns\n",
    "df_final_with_id = add_id_column(df_final)\n",
    "dropped_columns_with_id = add_id_column(dropped_columns)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3f1e6d2-6a0c-4d75-9f35-a508385720dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyodbc\n",
    "\n",
    "def connect_to_sql_server(server, database, username, password):\n",
    "    try:\n",
    "        # Connect to SQL Server using pyodbc\n",
    "        conn = pyodbc.connect(\n",
    "            f'DRIVER={{ODBC Driver 17 for SQL Server}};'\n",
    "            f'SERVER={server};'\n",
    "            f'DATABASE={database};'\n",
    "            f'UID={username};'\n",
    "            f'PWD={password}'\n",
    "        )\n",
    "        return conn\n",
    "    except Exception as e:\n",
    "        print(f\"Error connecting to SQL Server: {e}\")\n",
    "        return None\n",
    "\n",
    "def create_tables_and_load_data(server, database, username, password, df_merged, df_extracted, df_final):\n",
    "    try:\n",
    "        # Connect to SQL Server\n",
    "        conn = connect_to_sql_server(server, database, username, password)\n",
    "        if conn is None:\n",
    "            return\n",
    "        \n",
    "        # Create a cursor object using the connection\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        # Define table names and their corresponding DataFrames\n",
    "        tables = {\n",
    "            'df_merged': df_merged,\n",
    "            'df_extracted': df_extracted,\n",
    "            'AfterPreprocessing': df_final\n",
    "        }\n",
    "\n",
    "        # Iterate over tables to create them and insert data\n",
    "        for table_name, df in tables.items():\n",
    "            # Drop table if exists\n",
    "            cursor.execute(f\"IF OBJECT_ID('{table_name}', 'U') IS NOT NULL DROP TABLE {table_name};\")\n",
    "            conn.commit()\n",
    "\n",
    "            # Create SQL CREATE TABLE statement dynamically\n",
    "            create_table_sql = f\"CREATE TABLE {table_name} (\"\n",
    "\n",
    "            for column in df.columns:\n",
    "                sql_type = \"NVARCHAR(MAX)\"  # Default type for non-numeric columns\n",
    "                # Infer SQL types based on DataFrame dtypes\n",
    "                if pd.api.types.is_integer_dtype(df[column]):\n",
    "                    sql_type = \"INT\"\n",
    "                elif pd.api.types.is_float_dtype(df[column]):\n",
    "                    sql_type = \"FLOAT\"\n",
    "                elif pd.api.types.is_bool_dtype(df[column]):\n",
    "                    sql_type = \"BIT\"\n",
    "                elif pd.api.types.is_datetime64_any_dtype(df[column]):\n",
    "                    sql_type = \"DATETIME\"\n",
    "                elif pd.api.types.is_string_dtype(df[column]):\n",
    "                    max_length = df[column].str.len().max()\n",
    "                    sql_type = f\"NVARCHAR({max_length})\"\n",
    "\n",
    "                create_table_sql += f\"{column} {sql_type}, \"\n",
    "\n",
    "            create_table_sql = create_table_sql.rstrip(', ') + \");\"\n",
    "\n",
    "            # Execute the CREATE TABLE statement\n",
    "            cursor.execute(create_table_sql)\n",
    "            conn.commit()\n",
    "\n",
    "            # Insert data into the table\n",
    "            for index, row in df.iterrows():\n",
    "                data_values = []\n",
    "                for value in row:\n",
    "                    if pd.isnull(value):\n",
    "                        data_values.append(None)\n",
    "                    elif isinstance(value, (int, float)):\n",
    "                        data_values.append(value)\n",
    "                    else:\n",
    "                        data_values.append(str(value))  # Convert to string if not numeric or null\n",
    "\n",
    "                # Execute the INSERT statement with the prepared data values\n",
    "                insert_sql = f\"INSERT INTO {table_name} ({', '.join(df.columns)}) VALUES ({', '.join(['?'] * len(df.columns))})\"\n",
    "                cursor.execute(insert_sql, tuple(data_values))\n",
    "                conn.commit()\n",
    "\n",
    "            print(f'Table \"{table_name}\" created and data inserted successfully.')\n",
    "\n",
    "        # Close the cursor and connection\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "    \n",
    "    # Call the function to create tables and load data\n",
    "    #create_tables_and_load_data(server, database, username, password, df_merged, df_extracted, df_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "721fdc39-6c9b-4821-96bc-8df78ea71198",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_predictions_table_and_load_data(server, database, username, password, df_predictions, table_name_predictions):\n",
    "    try:\n",
    "        # Connect to SQL Server\n",
    "        conn = connect_to_sql_server(server, database, username, password)\n",
    "        if conn is None:\n",
    "            return\n",
    "        \n",
    "        # Create a cursor object using the connection\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        # Drop the table if it exists\n",
    "        cursor.execute(f\"IF OBJECT_ID('{table_name_predictions}', 'U') IS NOT NULL DROP TABLE {table_name_predictions};\")\n",
    "        conn.commit()\n",
    "\n",
    "        # Create SQL CREATE TABLE statement dynamically\n",
    "        create_table_sql = f\"CREATE TABLE {table_name_predictions} (\"\n",
    "\n",
    "        for column in df_predictions.columns:\n",
    "            sql_type = \"NVARCHAR(MAX)\"  # Default type for non-numeric columns\n",
    "            # Infer SQL types based on DataFrame dtypes\n",
    "            if pd.api.types.is_integer_dtype(df_predictions[column]):\n",
    "                sql_type = \"INT\"\n",
    "            elif pd.api.types.is_float_dtype(df_predictions[column]):\n",
    "                sql_type = \"FLOAT\"\n",
    "            elif pd.api.types.is_bool_dtype(df_predictions[column]):\n",
    "                sql_type = \"BIT\"\n",
    "            elif pd.api.types.is_datetime64_any_dtype(df_predictions[column]):\n",
    "                sql_type = \"DATETIME\"\n",
    "            elif pd.api.types.is_string_dtype(df_predictions[column]):\n",
    "                max_length = df_predictions[column].str.len().max()\n",
    "                sql_type = f\"NVARCHAR({max_length})\"\n",
    "\n",
    "            create_table_sql += f\"{column} {sql_type}, \"\n",
    "\n",
    "        create_table_sql = create_table_sql.rstrip(', ') + \");\"\n",
    "\n",
    "        # Execute the CREATE TABLE statement\n",
    "        cursor.execute(create_table_sql)\n",
    "        conn.commit()\n",
    "\n",
    "        # Insert data into the predictions table\n",
    "        for index, row in df_predictions.iterrows():\n",
    "            data_values = []\n",
    "            for value in row:\n",
    "                if pd.isnull(value):\n",
    "                    data_values.append(None)\n",
    "                elif isinstance(value, (int, float)):\n",
    "                    data_values.append(value)\n",
    "                else:\n",
    "                    data_values.append(str(value))  # Convert to string if not numeric or null\n",
    "\n",
    "            # Execute the INSERT statement with the prepared data values\n",
    "            insert_sql = f\"INSERT INTO {table_name_predictions} ({', '.join(df_predictions.columns)}) VALUES ({', '.join(['?'] * len(df_predictions.columns))})\"\n",
    "            cursor.execute(insert_sql, tuple(data_values))\n",
    "            conn.commit()\n",
    "\n",
    "        print(f'Table \"{table_name_predictions}\" created and data inserted successfully.')\n",
    "\n",
    "        # Close the cursor and connection\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "535b94b0-daca-483f-9b38-b972fdeeccd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQLServerLink file executed successfully.\n"
     ]
    }
   ],
   "source": [
    "print('SQLServerLink file executed successfully.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
